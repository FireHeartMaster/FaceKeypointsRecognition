{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(96, 96, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(30))\n",
    "    \n",
    "    return model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_CNN_model(model, optimizer, loss, metrics):\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    \n",
    "def train_CNN_model(model, X_train, y_train, epochs=100):\n",
    "    return model.fit(X_train, y_train, epochs=epochs, batch_size=200, verbose=1, validation_split=0.2)\n",
    "\n",
    "def save_CNN_model(model, filename):\n",
    "    model.save(filename + '.h5')\n",
    "    \n",
    "def load_CNN_model(filename):\n",
    "    return load_model(filename + '.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def load_data(test=False):\n",
    "    FTRAIN = 'FaceRecognitionFiles/data/training.csv'\n",
    "    FTEST = 'FaceRecognitionFiles/data/test.csv'\n",
    "    \n",
    "    fname = FTEST if test else FTRAIN\n",
    "    \n",
    "    df = read_csv(os.path.expanduser(fname)) # load dataframes\n",
    "    \n",
    "    # The Image column has pixel values separated by space\n",
    "    # convert the values to numpy arrays\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    df = df.dropna() # drop all rows that have missing values in them\n",
    "    \n",
    "    X = np.vstack(df['Image'].values) / 255.\n",
    "    X = X.astype(np.float32)\n",
    "    X = X.reshape(-1, 96, 96, 1) # return each images as 96 x 96 x 1\n",
    "    \n",
    "    if not test: # only FTRAIN has target columns\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48.) / 48. # scale target coordinates to [-1, 1] (Normalizing)\n",
    "        X, y = shuffle(X, y, random_state=42) # shuffle train data\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "        \n",
    "    return X, y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2140, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "X_train, y_train = load_data()\n",
    "\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_CNN_model()\n",
    "\n",
    "compile_CNN_model(model, optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = train_CNN_model(model, X_train, y_train, 100)\n",
    "\n",
    "# train_my_CNN_model returns a History object. History.history attribute is a record of training loss values and metrics\n",
    "# values at successive epochs, as well as validation loss values and validation metrics values (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_CNN_model(model, 'FaceRecognitionTrainedModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_CNN_model(filename):\n",
    "    return tf.keras.models.load_model(filename + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_CNN_model('FaceRecognitionTrainedModel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameraIndex = 0\n",
    "camera = cv2.VideoCapture(cameraIndex)\n",
    "\n",
    "cascadePath = 'FaceRecognitionFiles\\cascades\\haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(cascadePath)\n",
    "\n",
    "\n",
    "while True:\n",
    "    (gotImage, frame) = camera.read()\n",
    "    frame2 = np.copy(frame)\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.25, 6)\n",
    "    \n",
    "    #frame = cv2.rectangle(frame, (500,10), (620,65), (235,50,50), -1)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        \n",
    "        gray_face = gray[y:y+h, x:x+w]\n",
    "        color_face = frame[y:y+h, x:x+w]\n",
    "        \n",
    "    \n",
    "        gray_normalized = gray_face / 255.\n",
    "\n",
    "        original_shape = gray_face.shape\n",
    "\n",
    "        face_resized = cv2.resize(gray_normalized, (96,96), interpolation=cv2.INTER_AREA)\n",
    "        face_resized_copy = face_resized.copy()\n",
    "\n",
    "        face_resized = face_resized.reshape(1, 96, 96, 1)\n",
    "\n",
    "        keypoints = model.predict(face_resized)\n",
    "\n",
    "        # De-Normalize the keypoints values\n",
    "        keypoints = keypoints * 48 + 48\n",
    "\n",
    "        face_resized_color = cv2.resize(color_face, (96,96), interpolation=cv2.INTER_AREA)\n",
    "        face_resized_color2 = np.copy(face_resized_color)\n",
    "\n",
    "        points = []\n",
    "\n",
    "        for i, co in enumerate(keypoints[0][0::2]):\n",
    "            points.append((co, keypoints[0][1::2][i]))\n",
    "\n",
    "            \n",
    "        frame[y:y+h, x:x+w] = cv2.resize(face_resized_color, original_shape, interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        # Add KEYPOINTS to the frame2\n",
    "        for keypoint in points:\n",
    "            cv2.circle(face_resized_color2, keypoint, 1, (0,255,0), 1)     \n",
    "            \n",
    "        frame2[y:y+h, x:x+w] = cv2.resize(face_resized_color2, original_shape, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    cv2.imshow(\"Original Image\", frame)\n",
    "    cv2.imshow(\"keypoints\", frame2)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
